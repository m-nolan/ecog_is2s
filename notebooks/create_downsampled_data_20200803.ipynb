{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import pickle as pkl\n",
    "from aopy import datareader, datafilter\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('/Users/mickey/aoLab/code/analyze/')\n",
    "import tfspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Volumes/Samsung_T5/aoLab/Data/WirelessData/Goose_Multiscale_M1/'\n",
    "data_file_list = glob.glob(os.path.join(data_path,'*','*','*.clfp.dat'))\n",
    "print(len(data_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conservative downsampling method\n",
    "def downsample_binary_mask(mask,dsf):\n",
    "    mask_ds_len = int(np.round(len(mask)/dsf))\n",
    "    sample_idx = np.arange(0,len(mask),dsf)\n",
    "    mask_ds = np.zeros(mask_ds_len,dtype=bool)\n",
    "    for ds_idx, idx in enumerate(sample_idx):\n",
    "        ds_window = idx + np.arange(0,dsf)\n",
    "        ds_window = ds_window[ds_window < len(mask)]\n",
    "        mask_ds[ds_idx] = np.any(mask[ds_window])\n",
    "    if mask[sample_idx[-1]]: # if the last checked sample is bad, assume the rest of it is also bad\n",
    "        mask_ds[ds_idx+1:] = True\n",
    "    return mask_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ds_file(file_name,srate_down,overwrite):\n",
    "    save_dir = os.path.dirname(file_name)\n",
    "    file_basename = os.path.basename(file_name)\n",
    "    ds_file_name = os.path.join(save_dir,file_basename[:-4] + f'_ds{int(srate_down)}.dat')\n",
    "    ds_mask_file_name = os.path.join(save_dir,file_basename[:-4] + f'_ds{int(srate_down)}.mask.pkl')\n",
    "    # make filter ranges\n",
    "    f_range_list = [[0,10],\n",
    "                    [10,20],\n",
    "                    [20,30],\n",
    "                    [30,40],\n",
    "                    [40,50],\n",
    "                    [0,20],\n",
    "                    [10,30],\n",
    "                    [20,40],\n",
    "                    [30,50],\n",
    "                    [0,30],\n",
    "                    [10,40],\n",
    "                    [20,50]]\n",
    "    if os.path.exists(ds_file_name) and not overwrite:\n",
    "        print(f'{ds_file_name} already exists.')\n",
    "    else:\n",
    "        # load file\n",
    "        print(file_name)\n",
    "        data,exp,mask = datareader.load_ecog_clfp_data(file_name)\n",
    "        n_ch = exp['num_ch']\n",
    "        srate_in = exp['srate']\n",
    "        # downsample data\n",
    "        dsf = srate_in // srate_down\n",
    "        mask_all = mask['hf'] | mask['sat']\n",
    "        ds_n = int(np.ceil(data.shape[-1]/dsf))\n",
    "        data_down = np.zeros((n_ch,ds_n),dtype=np.float32)\n",
    "        mask_ds_hf = np.zeros((ds_n),dtype=bool)\n",
    "        ds_n_idx = len(mask_ds_hf)\n",
    "        mask_ds_hf[:ds_n_idx] = mask['hf'][::dsf]\n",
    "        mask_ds_sat = np.zeros((ds_n),dtype=bool)\n",
    "        mask_ds_sat = mask['sat'][::dsf]\n",
    "        if ds_n > ds_n_idx:\n",
    "            mask_ds_hf[-1] = mask_ds_hf[-2]\n",
    "            mask_ds_sat[-1] = mask_ds_sat[-2]\n",
    "        mask_ds = {'hf': mask_ds_hf,\n",
    "                   'sat': mask_ds_sat}\n",
    "        mask_ds_all = mask_ds['hf'] | mask_ds['sat']\n",
    "        print(f'{100*mask_ds_all.mean()}% of data masked')\n",
    "        print('downsampling data...')\n",
    "        print_progress_bar(0,n_ch)\n",
    "        for ch_idx in range(n_ch):\n",
    "            data_down[ch_idx,:] = np.float32(sp.signal.decimate(data[ch_idx,:],dsf))\n",
    "            print_progress_bar(ch_idx,n_ch)\n",
    "        data = data_down.copy()\n",
    "        del data_down\n",
    "        data[:,mask_ds_all] = 0.\n",
    "        # save file!\n",
    "        print(f'saving data to: {ds_file_name}')\n",
    "        data.tofile(ds_file_name)\n",
    "        print(f'saving mask to: {ds_mask_file_name}')\n",
    "        with open(ds_mask_file_name,'wb') as f:\n",
    "            pkl.dump(mask_ds,f)\n",
    "        # filter data\n",
    "        for f_range in f_range_list:\n",
    "            ds_filt_filename = file_basename[:-4] + f'_ds{int(srate_down)}_fl{f_range[0]}u{f_range[1]}.dat'\n",
    "            if os.path.exists(os.path.join(save_dir,ds_filt_filename)):\n",
    "                print(f'{os.path.join(save_dir,ds_filt_filename)} already exists...')\n",
    "            else:\n",
    "                print(f'Filtering data to {f_range}Hz')\n",
    "                n_tap = srate_down\n",
    "                a_fir = 1\n",
    "                pass_zero = f_range[0] == 0\n",
    "                if pass_zero:\n",
    "                    f_use = f_range[1]\n",
    "                else:\n",
    "                    f_use = f_range\n",
    "                b_fir = sp.signal.firwin(n_tap,f_use,fs=srate_down,pass_zero=pass_zero)\n",
    "                data_filt = np.float32(sp.signal.filtfilt(b_fir,a_fir,data,axis=-1))\n",
    "                # save data\n",
    "                print(f'Saving filtered data to {os.path.join(save_dir,ds_filt_filename)}')\n",
    "                data_filt.tofile(os.path.join(save_dir,ds_filt_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple progressbar, not tied to the iterator\n",
    "def print_progress_bar(count, total, status=''):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "\n",
    "    percents = round(100.0 * count / float(total), 1)\n",
    "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "\n",
    "    sys.stdout.write('[%s] %s%s ...%s\\r' % (bar, percents, '%', status))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srate_down = 250\n",
    "overwrite = True\n",
    "for ecog_file in data_file_list:\n",
    "    create_ds_file(ecog_file,srate_down,overwrite,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming those files: the '*.clfp.ds___.dat' doesn't play so well with the datareader.\n",
    "# this will not run if the poorly named files no longer exist - no need to remove.\n",
    "data_ds_file_list = glob.glob('/Volumes/Samsung_T5/aoLab/Data/WirelessData/Goose_Multiscale_M1/*/*/*.ds250.dat')\n",
    "for data_file in data_ds_file_list:\n",
    "    file_dir_name = os.path.dirname(data_file)\n",
    "    file_parts = os.path.basename(data_file).split('.')\n",
    "    new_data_basename = f'{file_parts[0]}.{file_parts[1]}.clfp_ds250.{file_parts[-1]}'\n",
    "    new_data_file = os.path.join(file_dir_name,new_data_basename)\n",
    "    print(f'old file: {data_file}')\n",
    "    print(f'new file: {new_data_file}')\n",
    "    os.system(f'mv {data_file} {new_data_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test ds data files! Try loading one and plotting a bit of it.\n",
    "data_test,exp,_ = datareader.load_ecog_clfp_data('/Volumes/Samsung_T5/aoLab/Data/WirelessData/Goose_Multiscale_M1/180328/006/rec006.LM1_ECOG_3.clfp_ds250.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_test.shape)\n",
    "f,ax = plt.subplots(1,1,figsize=(16,8))\n",
    "t_offset = 10\n",
    "plot_idx = np.arange(1000) + t_offset*250\n",
    "ax.plot(plot_idx/250,data_test[:,plot_idx].T+1000.*np.arange(exp['num_ch']));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :) now let's look at a single channel\n",
    "plt.plot(data_test[30,np.arange(500,1500)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good to me! How about a PSD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_t = 4\n",
    "bw = 2\n",
    "nw = window_t*bw/2\n",
    "n_taper = 2*nw - 1\n",
    "tapers = [window_t, nw, n_taper]\n",
    "sgram,f_sgram,ti_sgram,_ = tfspec.tfspec(data_test[30:31,:],sampling=250,tapers=tapers,dn=0.5)\n",
    "sgram = np.float32(sgram) # save some space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,1,figsize=(20,6))\n",
    "extent = (ti_sgram[0]/250, ti_sgram[-1]/250, f_sgram[0], f_sgram[-1])\n",
    "sgram_img = ax.imshow(10*np.log10(sgram[0,]).T,clim=(30,60),extent=extent,origin='bottom',aspect='auto')\n",
    "plt.colorbar(sgram_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks reasonable to me! I'll still probably run data quality checks and masks when loading these downsamples files, but this looks OK to me!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecog_is2s",
   "language": "python",
   "name": "ecog_is2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
