{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600452300157",
   "display_name": "Python 3.7.7 64-bit ('ecog_is2s': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# seq2seq training with DafaFile datasets\n",
    "Michael Nolan - 2020.09.11.3125"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aopy\n",
    "import ecog_is2s\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import os.path as path\n",
    "import glob\n",
    "\n",
    "# modules that aren't done yet\n",
    "sys.path.append('C:\\\\Users\\\\mickey\\\\aoLab\\\\code\\\\py4sid')\n",
    "# sys.path.append('/home/mickey/analyze/')\n",
    "import estimation\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get data files and create datafile objects\n",
    "data_path_root = 'E:\\\\aoLab\\\\Data\\\\WirelessData\\\\Goose_Multiscale_M1'\n",
    "data_path_day = path.join(data_path_root,'180325')\n",
    "data_file_list = glob.glob(path.join(data_path_day,'*\\\\*ECOG*clfp_ds250_fl0u10.dat'))\n",
    "print(f'files found:\\t{len(data_file_list)}')\n",
    "print(f'files: {data_file_list}')\n",
    "datafile_list = [aopy.data.DataFile(df) for df in data_file_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set time parameters - source, target and step lengths\n",
    "src_t = 1.0\n",
    "trg_t = 0.5\n",
    "step_t = 0.5\n",
    "scale_factor = 0.25\n",
    "transform = partial(aopy.data.data_transform_normalize,scale_factor=scale_factor)\n",
    "datafile_concat_dataset = aopy.data.DatafileConcatDataset([aopy.data.DatafileDataset(df,src_t,trg_t,step_t,transform=transform) for df in datafile_list])\n",
    "srate = datafile_concat_dataset.srate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src,trg = datafile_concat_dataset.__getitem__(1000)\n",
    "src_time = np.arange(src.shape[-1])/srate\n",
    "trg_time = np.arange(trg.shape[-1])/srate + src_t\n",
    "plot_ch_idx = 11\n",
    "f,ax = plt.subplots(1,1,dpi=100,figsize=(10,4))\n",
    "ax.plot(src_time,src[plot_ch_idx,:],label='src')\n",
    "ax.plot(trg_time,trg[plot_ch_idx,:],label='trg')\n",
    "ax.set_xlabel('time (s)')\n",
    "ax.set_ylabel('(a.u.)')\n",
    "ax.set_title('Normalized Data Sample')\n",
    "ax.legend(loc=0)"
   ]
  },
  {
   "source": [
    "## Linear Methods - baselines for comparison\n",
    "So: we have a data sampling interface that gives us access to the entire first day's data simultaneously. Those samples are normalized to be ~ in the range of \\[-1, 1\\].\n",
    "\n",
    "Now that I have that, I can easily (!) test out some linear prediction models to get baseline prediction method performance measures. The first and most basic (really basic) of these is a sample-wise MSE estimate of one-step signal dynamics. Here's an implementation of that:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def mse_est(datafile_concat_dataset):\n",
    "    n_sample = len(datafile_concat_dataset)\n",
    "    fve = np.zeros((datafile_concat_dataset.n_ch,n_sample))\n",
    "    n_ch = datafile_concat_dataset.n_ch\n",
    "    A_hat_all = np.zeros((n_ch,n_ch,n_sample))\n",
    "    for sample_idx in tqdm.tqdm(range(n_sample)):\n",
    "        # get sample\n",
    "        src, trg = datafile_concat_dataset.__getitem__(sample_idx)\n",
    "        # estimate dynamics (MSE)\n",
    "        X = src[:,:-1]\n",
    "        Y = src[:,1:]\n",
    "        A_hat = (Y @ X.T) @ np.linalg.inv(X @ X.T)\n",
    "        A_hat_all[:,:,sample_idx] = A_hat\n",
    "        # predict target activity\n",
    "        out = np.zeros(trg.shape)\n",
    "        out[:,0] = A_hat @ src[:,-1]\n",
    "        for est_idx in range(1,trg.shape[-1]):\n",
    "            out[:,est_idx] = A_hat @ out[:,est_idx-1]\n",
    "        # measure error\n",
    "        ss_err = np.var(trg-out, axis=-1)\n",
    "        ss_trg = np.var(-trg.mean(axis=-1)[:,None] + trg, axis=-1)\n",
    "        fve[:,sample_idx] = 1 - ss_err/ss_trg\n",
    "        # # plot prediction\n",
    "        # plt.plot(src_time,src[plot_ch_idx,:],label='src')\n",
    "        # plt.plot(trg_time,trg[plot_ch_idx,:],label='trg')\n",
    "        # plt.plot(trg_time,out[plot_ch_idx,:],label='out')\n",
    "        # plt.ylim([-1,1])\n",
    "        # plt.legend(loc=0)\n",
    "        # plt.xlabel('time (s)')\n",
    "        # plt.ylabel('(a.u.)')\n",
    "        # plt.title(f'MSE Prediction (fve = {fve[plot_ch_idx]:0.2f})')\n",
    "        # f = plt.gcf()\n",
    "    return fve, A_hat_all\n",
    "\n",
    "fve_mse, A_hat = mse_est(datafile_concat_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fve_mse[plot_ch_idx,fve_mse[plot_ch_idx,:]>-1.0],100,label='FVE')\n",
    "plt.axvline(1.0,color='r',label='max')\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('FVE')\n",
    "plt.title('MSE FVE, single-trial estimate')"
   ]
  },
  {
   "source": [
    "...not great! Let's take a look at the best case:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _best_sample_idx = np.nanargmax(fve_mse)\n",
    "# best_ch_idx = _best_sample_idx // len(datafile_concat_dataset)\n",
    "# best_sample_idx = _best_sample_idx % len(datafile_concat_dataset)\n",
    "# # get sample\n",
    "# src, trg = datafile_concat_dataset.__getitem__(best_sample_idx+2)\n",
    "# # estimate dynamics (MSE)\n",
    "# X = src[:,:-1]\n",
    "# Y = src[:,1:]\n",
    "# A_hat = (Y @ X.T) @ np.linalg.inv(X @ X.T)\n",
    "# # predict target activity\n",
    "# out = np.zeros(trg.shape)\n",
    "# out[:,0] = A_hat @ src[:,-1]\n",
    "# for est_idx in range(1,trg.shape[-1]):\n",
    "#     out[:,est_idx] = A_hat @ out[:,est_idx-1]\n",
    "# # measure error\n",
    "# ss_err = np.var(trg-out, axis=-1)\n",
    "# ss_trg = np.var(-trg.mean(axis=-1)[:,None] + trg, axis=-1)\n",
    "# # fve[:,sample_idx] = 1 - ss_err/ss_trg\n",
    "# # plot prediction\n",
    "# plt.plot(src_time,src[best_ch_idx,:],label='src')\n",
    "# plt.plot(trg_time,trg[best_ch_idx,:],label='trg')\n",
    "# plt.plot(trg_time,out[best_ch_idx,:],label='out')\n",
    "# plt.ylim([-1,1])\n",
    "# plt.legend(loc=0)\n",
    "# plt.xlabel('time (s)')\n",
    "# plt.ylabel('(a.u.)')\n",
    "# plt.title(f'Best MSE Prediction (fve = {fve_mse[best_ch_idx,best_sample_idx]:0.2f})')\n",
    "# # f = plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.coolwarm\n",
    "f,ax = plt.subplots(1,1,dpi=80)\n",
    "im = ax.imshow(A_hat[:,:,-5000],cmap)\n",
    "im.set_clim(vmin=-1.1,vmax=1.1)\n",
    "plt.colorbar(im)\n",
    "# ax[1].imshow(A_hat.std(axis=-1),origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(np.linalg.norm(A_hat,axis=(0,1))),500);"
   ]
  },
  {
   "source": [
    "## Subspace ID"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from synthetic_data import rand_lds_and_data\n",
    "from estimation import estimate_parameters_4sid, estimate_parameters_moments\n",
    "from util import plot_eigvals, normalize, plot_singularvals\n",
    "\n",
    "# x: LDS\n",
    "# y: measurement\n",
    "\n",
    "n, p = 16, 8 # x dimensions, y dimensions\n",
    "T = 30000 # time points\n",
    "\n",
    "## generate a system and simulate from it\n",
    "(A,B,C,D), (x,y) = rand_lds_and_data(T,n,p,eig_min=0.5,eig_max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the estimation code to get a linear system estimate:\n",
    "trial_idx = 1003\n",
    "src,trg = datafile_concat_dataset.__getitem__(trial_idx)\n",
    "lags = 80\n",
    "latent_dims = 10\n",
    "A_hat, C_hat = estimate_parameters_moments(src.T,lags,latent_dims)\n",
    "x0 = np.linalg.pinv(C_hat).dot(trg[:,0])\n",
    "x_out = np.zeros((latent_dims,trg.shape[-1]))\n",
    "x_out[:,0] = x0\n",
    "y_out = np.zeros(trg.shape)\n",
    "y_out[:,0] = C_hat @ x0\n",
    "for out_idx in range(1,trg.shape[-1]):\n",
    "    x_out[:,out_idx] = A_hat @ x_out[:,out_idx-1]\n",
    "    y_out[:,out_idx] = C_hat @ x_out[:,out_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot target and\n",
    "plt_ch_idx = 0 \n",
    "trg_time = np.arange(500)\n",
    "plt.plot(trg_time,trg[plt_ch_idx,:],label='trg')\n",
    "plt.plot(trg_time,y_out[plt_ch_idx,:],label='out')\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('time (ms)')\n",
    "plt.ylabel(f'ch {plt_ch_idx} (a.u.)')"
   ]
  }
 ]
}