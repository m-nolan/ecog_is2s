{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit ('ecog_is2s': conda)",
   "display_name": "Python 3.7.7 64-bit ('ecog_is2s': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fe8054fe0736511d0a995e424bd42fab5ba13013efdf79ed2907f82c79967e8d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "from os import makedirs, chmod\n",
    "import glob\n",
    "import functools\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import tqdm\n",
    "\n",
    "import aopy\n",
    "import ecog_is2s\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(data,train_valid_test_frac=(0.8,0.2,0.0)):\n",
    "    # channel mask\n",
    "    ch_var = data.var(axis=0)\n",
    "    ch_var_mean = ch_var.mean()\n",
    "    ch_var_std = ch_var.std()\n",
    "    ch_idx = np.logical_and(ch_var > ch_var_mean-1.5*ch_var_std, ch_var < ch_var_mean+1.5*ch_var_std)\n",
    "    # partition data\n",
    "    n_samples, _ = data.shape\n",
    "    n_ch = sum(ch_idx)\n",
    "    n_train_samples = round(n_samples*train_valid_test_frac[0])\n",
    "    n_valid_samples = round(n_samples*train_valid_test_frac[1])\n",
    "    n_test_samples = round(n_samples*train_valid_test_frac[2])\n",
    "    train_idx = np.arange(0,n_train_samples)\n",
    "    valid_idx = np.arange(n_train_samples,n_train_samples+n_valid_samples)\n",
    "    test_idx = np.arange(n_train_samples+n_valid_samples,n_samples)\n",
    "    train_data = data[train_idx,:][:,ch_idx]\n",
    "    valid_data = data[valid_idx,:][:,ch_idx]\n",
    "    test_data = data[test_idx,:][:,ch_idx]\n",
    "    train_data = train_data - train_data.mean()\n",
    "    valid_data = valid_data - valid_data.mean()\n",
    "    test_data = test_data - test_data.mean()\n",
    "    return train_data, valid_data, test_data, ch_idx\n",
    "\n",
    "def train_AR_model(train_data,model_order):\n",
    "    model = VAR(train_data)\n",
    "    model_fit = model.fit(model_order)\n",
    "    return model_fit\n",
    "\n",
    "def compute_err_metrics(pred,trg,axis=0):\n",
    "    assert pred.shape == trg.shape, \"pred and trg arrays must have equal shape\"\n",
    "    n_sample, n_ch = pred.shape\n",
    "    err = pred-trg\n",
    "    # mean square error\n",
    "    mse = np.sqrt(np.mean(err**2,axis=axis))\n",
    "    # relative prediction error, MSE scaled by target \\sigma\n",
    "    trg_std = trg.std(axis=axis)\n",
    "    rpe = mse/trg_std\n",
    "    # element-wise correlation coefficient\n",
    "    corr = np.diag(np.corrcoef(pred,trg,rowvar=False)[:n_ch,n_ch:])\n",
    "    return mse, rpe, corr\n",
    "\n",
    "def compute_prediction_metrics(test_data,model_fit,pred_window_T,bin_T,p_lim=[2.5, 97.5],srate=250):\n",
    "    n_sample, n_ch = test_data.shape\n",
    "    time = np.arange(pred_window_T*srate)/srate\n",
    "    bin_T_left_edge = np.arange(pred_window_T,step=bin_T)\n",
    "    bin_T_right_edge = bin_T_left_edge + bin_T\n",
    "    fit_order = model_fit.k_ar\n",
    "    pred_window_n = int(pred_window_T*srate + fit_order)\n",
    "    n_pred_window = n_sample//pred_window_n\n",
    "    n_time_bin = len(bin_T_left_edge)\n",
    "    mse = np.empty((n_pred_window,n_ch))\n",
    "    mse_all = np.empty((n_pred_window))\n",
    "    mse_bin = np.empty((n_pred_window,n_ch,n_time_bin))\n",
    "    mse_bin_all = np.empty((n_pred_window,n_time_bin))\n",
    "    rpe = np.empty((n_pred_window,n_ch))\n",
    "    rpe_all = np.empty((n_pred_window))\n",
    "    rpe_bin = np.empty((n_pred_window,n_ch,n_time_bin))\n",
    "    rpe_bin_all = np.empty((n_pred_window,n_time_bin))\n",
    "    corr = np.empty((n_pred_window,n_ch))\n",
    "    # corr_all = np.empty((n_pred_window))\n",
    "    corr_bin = np.empty((n_pred_window,n_ch,n_time_bin))\n",
    "    # corr_bin_all = np.empty((n_pred_window,n_time_bin))\n",
    "    for pred_win_idx in tqdm.tqdm(range(n_pred_window)):\n",
    "        window_idx = pred_win_idx*pred_window_n + np.arange(pred_window_n)\n",
    "        data_window = test_data[window_idx,:]\n",
    "        pred = model_fit.forecast(data_window[:fit_order,:],steps=pred_window_n-fit_order)\n",
    "        ## time bins\n",
    "        for tb_idx in range(n_time_bin):\n",
    "            bin_idx = np.logical_and(time >= bin_T_left_edge[tb_idx], time < bin_T_right_edge[tb_idx])\n",
    "            mse_bin[pred_win_idx,:,tb_idx], rpe_bin[pred_win_idx,:,tb_idx], corr_bin[pred_win_idx,:,tb_idx] = compute_err_metrics(pred[bin_idx,:],data_window[fit_order:,:][bin_idx,:])\n",
    "            mse_bin_all[pred_win_idx,tb_idx], rpe_bin_all[pred_win_idx,tb_idx], _ = compute_err_metrics(pred[bin_idx,:],data_window[fit_order:,:][bin_idx,:],axis=(0,1))\n",
    "        mse[pred_win_idx,:], rpe[pred_win_idx,:], corr[pred_win_idx,:] = compute_err_metrics(pred,data_window[fit_order:,:])\n",
    "        mse_all[pred_win_idx], rpe_all[pred_win_idx], _ = compute_err_metrics(pred,data_window[fit_order:,:],axis=(0,1))\n",
    "        trg_fft = np.fft.fft(data_window[fit_order:,:],axis=0)[:int(pred_window_T*srate/2),:]\n",
    "        pred_fft = np.fft.fft(pred,axis=0)[:int(pred_window_T*srate/2),:]\n",
    "        f_fft = np.fft.fftfreq(srate,d=1/srate)[:int(pred_window_T*srate/2)]\n",
    "        # add coherence stats here!\n",
    "    # get stats from sample distributions\n",
    "    stat_dict = {\n",
    "        'mse_mean': mse.mean(axis=0),\n",
    "        'mse_95ci': np.percentile(mse,p_lim,axis=0),\n",
    "        'mse_bin_mean': mse_bin.mean(axis=0),\n",
    "        'mse_bin_95ci': np.percentile(mse_bin,p_lim,axis=0),\n",
    "        'rpe_mean': rpe.mean(axis=0),\n",
    "        'rpe_95ci': np.percentile(rpe,p_lim,axis=0),\n",
    "        'rpe_bin_mean': rpe_bin.mean(axis=0),\n",
    "        'rpe_bin_95ci': np.percentile(rpe_bin,p_lim,axis=0),\n",
    "        'corr_mean': np.tanh(np.arctanh(corr).mean(axis=0)),\n",
    "        'corr_95ci': np.percentile(corr,p_lim,axis=0),\n",
    "        'corr_bin_mean': np.tanh(np.arctanh(corr_bin).mean(axis=0)),\n",
    "        'corr_bin_95ci': np.percentile(corr_bin,p_lim,axis=0)\n",
    "    }\n",
    "    stat_dict_all = {\n",
    "        'mse_mean': mse_all.mean(axis=0),\n",
    "        'mse_95ci': np.percentile(mse_all,p_lim,axis=0),\n",
    "        'mse_bin_mean': mse_bin_all.mean(axis=0),\n",
    "        'mse_bin_95ci': np.percentile(mse_bin_all,p_lim,axis=0),\n",
    "        'rpe_mean': rpe_all.mean(axis=0),\n",
    "        'rpe_95ci': np.percentile(rpe_all,p_lim,axis=0),\n",
    "        'rpe_bin_mean': rpe_bin_all.mean(axis=0),\n",
    "        'rpe_bin_95ci': np.percentile(rpe_bin_all,p_lim,axis=0),\n",
    "    }\n",
    "    return stat_dict, stat_dict_all, bin_T_left_edge\n",
    "\n",
    "def create_metric_stat_table(stat_dict):\n",
    "    df = pd.DataFrame(data = {\n",
    "        'mse_mean': [stat_dict['mse_mean']],\n",
    "        'mse_ci_2.5': [stat_dict['mse_95ci'][0,]],\n",
    "        'mse_ci_97.5': [stat_dict['mse_95ci'][1,]],\n",
    "        'rpe_mean': [stat_dict['rpe_mean']],\n",
    "        'rpe_ci_2.5': [stat_dict['rpe_95ci'][0,]],\n",
    "        'rpe_ci_97.5': [stat_dict['rpe_95ci'][1,]]\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_metric_bin_stat_table(stat_dict):\n",
    "    df = pd.DataFrame(data = {\n",
    "        'mse_bin_mean': stat_dict['mse_bin_mean'],\n",
    "        'mse_ci_2.5': stat_dict['mse_bin_95ci'][0,],\n",
    "        'mse_ci_97.5': stat_dict['mse_bin_95ci'][1,],\n",
    "        'rpe_bin_mean': stat_dict['rpe_bin_mean'],\n",
    "        'rpe_ci_2.5': stat_dict['rpe_bin_95ci'][0,],\n",
    "        'rpe_ci_97.5': stat_dict['rpe_bin_95ci'][1,]\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a single file data array\n",
    "# file list to dataset\n",
    "data_path_root = 'C:\\\\Users\\\\mickey\\\\aoLab\\\\Data\\\\WirelessData\\\\Goose_Multiscale_M1'\n",
    "data_path_day = path.join(data_path_root,'18032*')\n",
    "data_file_list = glob.glob(path.join(data_path_day,'0[0-9]*\\\\*ECOG*clfp_ds250_fl0u10.dat'))\n",
    "# data_file_list = glob.glob(path.join(data_path_day,'0[0-9]*\\\\*ECOG*clfp_ds250.dat'))\n",
    "device = 'cpu'\n",
    "print('mounting to device: {}'.format(device))\n",
    "print(f'files found:\\t{len(data_file_list)}')\n",
    "print(f'files: {data_file_list}')\n",
    "datafile_list = [aopy.data.DataFile(df) for df in data_file_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop across all files to:\n",
    "#   - train AR model\n",
    "#   - compute error metrics\n",
    "#   - create error table\n",
    "# concatenate all error tables\n",
    "# save table\n",
    "mask_buffer_T = 60\n",
    "model_order = 10\n",
    "pred_window_T = 1\n",
    "bin_T = 0.1\n",
    "stat_df_list = []\n",
    "stat_all_df_list = []\n",
    "stat_bin_df_list = []\n",
    "for df_idx, df in enumerate(datafile_list):\n",
    "    print(f'({df_idx+1}/{len(datafile_list)}) file {df.data_file_path}')\n",
    "    data = df.read().T\n",
    "    mask = df.data_mask\n",
    "    srate = df.srate\n",
    "    # widen masked regions - no chances\n",
    "    print(f'masking data...')\n",
    "    mask_buffer_n = mask_buffer_T*srate\n",
    "    fill_mask = sp.signal.convolve(mask,np.ones(mask_buffer_n,dtype=bool),mode='same')\n",
    "    data = data[~fill_mask,:]\n",
    "    train_data, valid_data, test_data, ch_idx = partition_data(data)\n",
    "    # train the linear model\n",
    "    print('fitting model...')\n",
    "    model_fit = train_AR_model(train_data,model_order)\n",
    "    # compute validation metrics\n",
    "    print('computing metrics:')\n",
    "    stat_dict, stat_dict_all, bin_T_left_edge = compute_prediction_metrics(valid_data,model_fit,pred_window_T,bin_T,srate=srate)\n",
    "    # convert to tables\n",
    "    _stat_df = create_metric_stat_table(stat_dict)\n",
    "    _stat_all_df = create_metric_stat_table(stat_dict_all)\n",
    "    _stat_bin_df = create_metric_bin_stat_table(stat_dict_all)\n",
    "    stat_df_list.append(_stat_df)\n",
    "    stat_all_df_list.append(_stat_all_df)\n",
    "    stat_bin_df_list.append(_stat_bin_df)\n",
    "stat_df = pd.concat(stat_df_list)\n",
    "stat_df['file_path'] = data_file_list\n",
    "stat_all_df = pd.concat(stat_all_df_list)\n",
    "stat_all_df['file_path'] = data_file_list\n",
    "stat_bin_df = pd.concat(stat_bin_df_list)\n",
    "stat_bin_df['file_path'] = data_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_bin_df = pd.concat(stat_bin_df_list)\n",
    "stat_bin_df['file_path'] = data_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save performance metric table for this analysis\n",
    "date_str = datetime.datetime.strftime(datetime.datetime.now(),'%Y%m%d%H%M%S')\n",
    "analysis_path = f'D:\\\\Users\\\\mickey\\\\Data\\\\analysis\\\\prediction_p{model_order}_{pred_window_T}s_{date_str}'\n",
    "if not path.exists(analysis_path):\n",
    "    os.makedirs(analysis_path)\n",
    "stat_df.to_csv(path.join(analysis_path,'prediction_metric_stats.csv'))\n",
    "stat_all_df.to_csv(path.join(analysis_path,'prediction_metric_all_stats.csv'))\n",
    "stat_bin_df.to_csv(path.join(analysis_path,'prediction_metric_bin_stats.csv))\n",
    "param_dict = {\n",
    "    'bin_t': bin_T_left_edge,\n",
    "    'pred_t': pred_window_T,\n",
    "    'bin_t': bin_T,\n",
    "    'model_p': model_order\n",
    "}\n",
    "np.savez(path.join(analysis_path,'param.npz'),param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = datetime.datetime.strftime(datetime.datetime.now(),'%Y%m%d%H%M%S')\n",
    "analysis_path = f'D:\\\\Users\\\\mickey\\\\Data\\\\analysis\\\\prediction_p{model_order}_{pred_window_T}s_{date_str}'\n",
    "print(analysis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_bin_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}