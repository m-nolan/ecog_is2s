{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "fe8054fe0736511d0a995e424bd42fab5ba13013efdf79ed2907f82c79967e8d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "from os import makedirs, chmod\n",
    "import glob\n",
    "import functools\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import tqdm\n",
    "\n",
    "import aopy\n",
    "import ecog_is2s\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a single file data array\n",
    "# file list to dataset\n",
    "data_path_root = 'C:\\\\Users\\\\mickey\\\\aoLab\\\\Data\\\\WirelessData\\\\Goose_Multiscale_M1'\n",
    "data_path_day = path.join(data_path_root,'18032*')\n",
    "data_file_list = glob.glob(path.join(data_path_day,'0[0-9]*\\\\*ECOG*clfp_ds250_fl0u10.dat'))\n",
    "# data_file_list = glob.glob(path.join(data_path_day,'0[0-9]*\\\\*ECOG*clfp_ds250.dat'))\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print('mounting to device: {}'.format(device))\n",
    "print(f'files found:\\t{len(data_file_list)}')\n",
    "print(f'files: {data_file_list}')\n",
    "datafile_list = [aopy.data.DataFile(df) for df in data_file_list]\n",
    "file_idx = 6\n",
    "data = datafile_list[file_idx].read().T\n",
    "mask = datafile_list[file_idx].data_mask\n",
    "srate = datafile_list[file_idx].srate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mask = sp.signal.convolve(mask,np.ones(60*srate,dtype=bool),mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile_list[5].data_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test/train splits\n",
    "data = data[~fill_mask,:]\n",
    "ch_var = data.var(axis=0)\n",
    "ch_var_mean = ch_var.mean()\n",
    "ch_var_std = ch_var.std()\n",
    "ch_idx = np.logical_and(ch_var > ch_var_mean-1.5*ch_var_std, ch_var < ch_var_mean+1.5*ch_var_std)\n",
    "n_samples, _ = data.shape\n",
    "n_ch = sum(ch_idx)\n",
    "train_test_valid_frac = (.8, 0.1, 0.1)\n",
    "n_train_samples = round(n_samples*train_test_valid_frac[0])\n",
    "n_valid_samples = round(n_samples*train_test_valid_frac[1])\n",
    "n_test_samples = round(n_samples*train_test_valid_frac[2])\n",
    "train_idx = np.arange(0,n_train_samples)\n",
    "valid_idx = np.arange(n_train_samples,n_train_samples+n_valid_samples)\n",
    "test_idx = np.arange(n_train_samples+n_valid_samples,n_samples)\n",
    "train_data = data[train_idx,:][:,ch_idx]\n",
    "valid_data = data[valid_idx,:][:,ch_idx]\n",
    "test_data = data[test_idx,:][:,ch_idx]\n",
    "train_data = train_data - train_data.mean()\n",
    "valid_data = valid_data - valid_data.mean()\n",
    "test_data = test_data - test_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR model\n",
    "from statsmodels.tsa.api import VAR\n",
    "model = VAR(train_data)\n",
    "# model.select_order(10)\n",
    "model_fit = model.fit(10)\n",
    "# model = VARMAX(data, order=(10, 10))\n",
    "# model_fit = model.fit(disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_order = model_fit.k_ar\n",
    "# print(fit_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 20000\n",
    "pred_data = model_fit.forecast(test_data[start_idx:start_idx+fit_order,:], steps=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(srate)/srate,test_data[start_idx+fit_order:start_idx+250+fit_order,0],label='trg')\n",
    "plt.plot(np.arange(srate)/srate,pred_data[:,0],label='pred');\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('amp ($\\mu$V)')\n",
    "plt.title(f'p={fit_order} (r = {np.corrcoef(test_data[start_idx+fit_order:start_idx+250+fit_order,0],pred_data[:,0])[0,1]:0.3f})')\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_window_T = 1\n",
    "pred_window_n = pred_window_T*srate + fit_order\n",
    "n_pred_window = len(test_idx)//pred_window_n\n",
    "mse = np.empty((n_pred_window,n_ch))\n",
    "rpe = np.empty((n_pred_window,n_ch))\n",
    "corr = np.empty((n_pred_window,n_ch))\n",
    "ft_corr = np.empty((n_pred_window,n_ch))\n",
    "p_lim = [2.5,97.5]\n",
    "for pred_win_idx in tqdm.tqdm(range(n_pred_window)):\n",
    "    window_idx = pred_win_idx*pred_window_n + np.arange(pred_window_n)\n",
    "    data_window = data[window_idx,:]\n",
    "    pred = model_fit.forecast(data_window[:fit_order,:],steps=pred_window_n-fit_order)\n",
    "    # mse\n",
    "    mse[pred_win_idx,:] = np.sqrt(np.mean((data_window[fit_order:,:] - pred)**2, axis=0))\n",
    "    data_std = data_window[fit_order:,:].std(axis=0)\n",
    "    rpe[pred_win_idx,:] = mse[pred_win_idx,:]/data_std\n",
    "    corr[pred_win_idx,:] = np.diag(np.corrcoef(pred,data_window[fit_order:,:],rowvar=False)[:n_ch,n_ch:]) #take full corrcoef matrix, cut to cross-terms, take the diagonal.\n",
    "ft_corr = np.arctanh(corr)\n",
    "mse_mean = mse.mean(axis=0)\n",
    "mse_95ci = np.percentile(mse,p_lim,axis=0)\n",
    "rpe_mean = rpe.mean(axis=0)\n",
    "rpe_95ci = np.percentile(rpe,p_lim,axis=0)\n",
    "ft_corr_mean = ft_corr.mean(axis=0)\n",
    "ft_corr_95ci = np.percentile(ft_corr,p_lim,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred - real correlation, fisher transform\n",
    "def metric_channel_plot(metric,p_val,title,ylabel):\n",
    "    metric_mean = metric.mean(axis=0)\n",
    "    metric_95ci = np.percentile(metric,p_val,axis=0)\n",
    "    f = plt.figure(figsize=(20,2),dpi=100)\n",
    "    plt.violinplot(metric);\n",
    "    plt.plot(np.arange(1,n_ch+1),metric_mean,'.',label='mean')\n",
    "    plt.plot(np.arange(1,n_ch+1),metric_95ci.T,'.',label='95% CI')\n",
    "    plt.xlabel('ch.')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=0)\n",
    "    return f\n",
    "f = metric_channel_plot(ft_corr,p_lim,f'Fisher Transform Correlation (p = {fit_order})','z')\n",
    "f.savefig(f'td_corr_p{fit_order}_10Hz.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = metric_channel_plot(rpe,p_lim,f'Relative Prediction Error (p = {fit_order})','rpe')\n",
    "plt.ylim(0,5)\n",
    "plt.axhline(1,color='k',alpha=0.5)\n",
    "f.savefig(f'rpe_p{fit_order}_10Hz.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_err_metrics(pred,trg,axis=0):\n",
    "    assert pred.shape == trg.shape, \"pred and trg arrays must have equal shape\"\n",
    "    n_sample, n_ch = pred.shape\n",
    "    err = pred-trg\n",
    "    # mean square error\n",
    "    mse = np.sqrt(np.mean(err**2,axis=axis))\n",
    "    # relative prediction error, MSE scaled by target \\sigma\n",
    "    trg_std = trg.std(axis=axis)\n",
    "    rpe = mse/trg_std\n",
    "    # element-wise correlation coefficient\n",
    "    corr = np.diag(np.corrcoef(pred,trg,rowvar=False)[:n_ch,n_ch:])\n",
    "    return mse, rpe, corr\n",
    "\n",
    "def compute_prediction_metrics(test_data,model_fit,pred_window_T,bin_T,p_lim=[2.5, 97.5],srate=250):\n",
    "    n_sample, n_ch = test_data.shape\n",
    "    time = np.arange(pred_window_T*srate)/srate\n",
    "    bin_T_left_edge = np.arange(pred_window_T,step=bin_T)\n",
    "    bin_T_right_edge = bin_T_left_edge + bin_T\n",
    "    fit_order = model_fit.k_ar\n",
    "    pred_window_n = int(pred_window_T*srate + fit_order)\n",
    "    n_pred_window = len(test_idx)//pred_window_n\n",
    "    n_time_bin = len(bin_T_left_edge)\n",
    "    mse = np.empty((n_pred_window,n_ch))\n",
    "    mse_all = np.empty((n_pred_window))\n",
    "    mse_bin = np.empty((n_pred_window,n_ch,n_time_bin))\n",
    "    mse_bin_all = np.empty((n_pred_window,n_time_bin))\n",
    "    rpe = np.empty((n_pred_window,n_ch))\n",
    "    rpe_all = np.empty((n_pred_window))\n",
    "    rpe_bin = np.empty((n_pred_window,n_ch,n_time_bin))\n",
    "    rpe_bin_all = np.empty((n_pred_window,n_time_bin))\n",
    "    corr = np.empty((n_pred_window,n_ch))\n",
    "    # corr_all = np.empty((n_pred_window))\n",
    "    corr_bin = np.empty((n_pred_window,n_ch,n_time_bin))\n",
    "    # corr_bin_all = np.empty((n_pred_window,n_time_bin))\n",
    "    for pred_win_idx in tqdm.tqdm(range(n_pred_window)):\n",
    "        window_idx = pred_win_idx*pred_window_n + np.arange(pred_window_n)\n",
    "        data_window = test_data[window_idx,:]\n",
    "        pred = model_fit.forecast(data_window[:fit_order,:],steps=pred_window_n-fit_order)\n",
    "        ## time bins\n",
    "        for tb_idx in range(n_time_bin):\n",
    "            bin_idx = np.logical_and(time >= bin_T_left_edge[tb_idx], time < bin_T_right_edge[tb_idx])\n",
    "            mse_bin[pred_win_idx,:,tb_idx], rpe_bin[pred_win_idx,:,tb_idx], corr_bin[pred_win_idx,:,tb_idx] = compute_err_metrics(pred[bin_idx,:],data_window[fit_order:,:][bin_idx,:])\n",
    "            mse_bin_all[pred_win_idx,tb_idx], rpe_bin_all[pred_win_idx,tb_idx], _ = compute_err_metrics(pred[bin_idx,:],data_window[fit_order:,:][bin_idx,:],axis=(0,1))\n",
    "        mse[pred_win_idx,:], rpe[pred_win_idx,:], corr[pred_win_idx,:] = compute_err_metrics(pred,data_window[fit_order:,:])\n",
    "        mse_all[pred_win_idx], rpe_all[pred_win_idx], _ = compute_err_metrics(pred,data_window[fit_order:,:],axis=(0,1))\n",
    "        trg_fft = np.fft.fft(data_window[fit_order:,:],axis=0)[:int(pred_window_T*srate/2),:]\n",
    "        pred_fft = np.fft.fft(pred,axis=0)[:int(pred_window_T*srate/2),:]\n",
    "        f_fft = np.fft.fftfreq(srate,d=1/srate)[:int(pred_window_T*srate/2)]\n",
    "        # add coherence stats here!\n",
    "    # get stats from sample distributions\n",
    "    stat_dict = {\n",
    "        'mse_mean': mse.mean(axis=0),\n",
    "        'mse_95ci': np.percentile(mse,p_lim,axis=0),\n",
    "        'mse_bin_mean': mse_bin.mean(axis=0),\n",
    "        'mse_bin_95ci': np.percentile(mse_bin,p_lim,axis=0),\n",
    "        'rpe_mean': rpe.mean(axis=0),\n",
    "        'rpe_95ci': np.percentile(rpe,p_lim,axis=0),\n",
    "        'rpe_bin_mean': rpe_bin.mean(axis=0),\n",
    "        'rpe_bin_95ci': np.percentile(rpe_bin,p_lim,axis=0),\n",
    "        'corr_mean': np.tanh(np.arctanh(corr).mean(axis=0)),\n",
    "        'corr_95ci': np.percentile(corr,p_lim,axis=0),\n",
    "        'corr_bin_mean': np.tanh(np.arctanh(corr_bin).mean(axis=0)),\n",
    "        'corr_bin_95ci': np.percentile(corr_bin,p_lim,axis=0)\n",
    "    }\n",
    "    stat_dict_all = {\n",
    "        'mse_mean': mse_all.mean(axis=0),\n",
    "        'mse_95ci': np.percentile(mse_all,p_lim,axis=0),\n",
    "        'mse_bin_mean': mse_bin_all.mean(axis=0),\n",
    "        'mse_bin_95ci': np.percentile(mse_bin_all,p_lim,axis=0),\n",
    "        'rpe_mean': rpe_all.mean(axis=0),\n",
    "        'rpe_95ci': np.percentile(rpe_all,p_lim,axis=0),\n",
    "        'rpe_bin_mean': rpe_bin_all.mean(axis=0),\n",
    "        'rpe_bin_95ci': np.percentile(rpe_bin_all,p_lim,axis=0),\n",
    "    }\n",
    "    return stat_dict, stat_dict_all, bin_T_left_edge\n",
    "\n",
    "# def compute_agg_stat_dataframe(stat_dict,)\n",
    "\n",
    "pred_window_T = 1.0\n",
    "bin_T = 0.1\n",
    "metric_stat_dict, metric_stat_dict_all, bin_time = compute_prediction_metrics(test_data,model_fit,pred_window_T,bin_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(bin_time,metric_stat_dict['rpe_bin_95ci'][0,:],metric_stat_dict['rpe_bin_95ci'][1,:],alpha=0.3)\n",
    "plt.plot(bin_time,metric_stat_dict['rpe_bin_mean']);\n",
    "plt.xlabel('time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch_idx in range(n_ch):\n",
    "    plt.fill_between(bin_time,metric_stat_dict['corr_bin_95ci'][0,ch_idx,:],metric_stat_dict['corr_bin_95ci'][1,ch_idx,:],alpha=0.3)\n",
    "    plt.plot(bin_time,metric_stat_dict['corr_bin_mean'][ch_idx,:]);\n",
    "plt.axhline(1,color='k',linestyle=':')\n",
    "plt.ylim(0,1.1)\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('RPE (a.u.)')\n",
    "plt.title(f'Relative Prediction Accuracy, p = {fit_order}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metric_stat_table(stat_dict):\n",
    "    df = pd.DataFrame(data = {\n",
    "        'mse_mean': [stat_dict['mse_mean']],\n",
    "        'mse_ci_2.5': [stat_dict['mse_95ci'][0,]],\n",
    "        'mse_ci_97.5': [stat_dict['mse_95ci'][1,]],\n",
    "        'rpe_mean': [stat_dict['rpe_mean']],\n",
    "        'rpe_ci_2.5': [stat_dict['rpe_95ci'][0,]],\n",
    "        'rpe_ci_97.5': [stat_dict['rpe_95ci'][1,]]\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "stat_df = create_metric_stat_table(metric_stat_dict)\n",
    "stat_all_df = create_metric_stat_table(metric_stat_dict_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_metric_stat_table(metric_stat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_stat_dict_all['mse_bin_mean']"
   ]
  }
 ]
}