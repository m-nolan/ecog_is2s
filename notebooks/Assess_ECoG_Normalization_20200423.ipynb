{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aopy import datareader, datafilter\n",
    "from ecog_is2s import EcogDataloader, Training, Encoder, Decoder, Seq2Seq, Util, Tvregdiff\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SequentialSampler, BatchSampler, SubsetRandomSampler\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import sklearn\n",
    "import scipy as sp\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "# import progressbar as pb\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import pickle as pkl\n",
    "\n",
    "# import argparse # add back in once this runs\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load, preprocess example data (same as training, so sue me)\n",
    "# seed RNG for pytorch/np\n",
    "SEED = 5050\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# set device - CUDA if you've got it\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('mounting to device: {}'.format(device))\n",
    "\n",
    "# load data\n",
    "platform_name = sys.platform\n",
    "if platform_name == 'darwin':\n",
    "    # local machine\n",
    "    data_file_full_path = '/Volumes/Samsung_T5/aoLab/Data/WirelessData/Goose_Multiscale_M1/180325/001/rec001.LM1_ECOG_3.clfp.dat'\n",
    "    mask_file_path = \"/Volumes/Samsung_T5/aoLab/Data/WirelessData/Goose_Multiscale_M1/180325/001/rec001.LM1_ECOG_3.clfp.mask.pkl\"\n",
    "    model_save_dir_path = '/Volumes/Samsung_T5/aoLab/Data/models/pyt/seq2seq/'\n",
    "elif platform_name == 'linux2':\n",
    "    # HYAK, baby!\n",
    "    data_file_full_path = '/gscratch/stf/manolan/Data/WirelessData/Goose_Multiscale_M1/180325/001/rec001.LM1_ECOG_3.clfp.dat'\n",
    "    mask_file_path = \"/gscratch/stf/manolan/Data/WirelessData/Goose_Multiscale_M1/180325/001/rec001.LM1_ECOG_3.clfp.mask.pkl\"\n",
    "elif platform_name == 'linux':\n",
    "    # google cloud, don't fail me now\n",
    "    data_file_full_path = '/home/mickey/rec001.LM1_ECOG_3.clfp.dat'\n",
    "    mask_file_path = '/home/mickey/rec001.LM1_ECOG_3.clfp.mask.pkl'\n",
    "    model_save_dir_path = '/home/mickey/models/pyt/seq2seq/'\n",
    "\n",
    "# make sure the output directory actually exists\n",
    "if not os.path.exists(model_save_dir_path):\n",
    "    os.makedirs(model_save_dir_path)\n",
    "\n",
    "data_in, data_param, data_mask = datareader.load_ecog_clfp_data(data_file_name=data_file_full_path)\n",
    "srate_in= data_param['srate']\n",
    "num_ch = data_param['num_ch']\n",
    "# we already found the appropriate data masks, so just load them in\n",
    "with open(mask_file_path, 'rb') as f:\n",
    "    mask_data = pkl.load(f)\n",
    "hf_mask = mask_data[\"hf\"]\n",
    "sat_mask = mask_data[\"sat\"]\n",
    "\n",
    "# mask data array, remove obvious outliers\n",
    "data_in[:,np.logical_or(hf_mask,sat_mask)] = 0.\n",
    "\n",
    "# downsample data\n",
    "srate_down = 250\n",
    "\n",
    "# create dataset object from file\n",
    "srate = srate_in\n",
    "# data_in = np.double(data_in[:,:120*srate])\n",
    "# enc_len = args.encoder_depth\n",
    "# dec_len = args.decoder_depth\n",
    "# seq_len = enc_len+dec_len # use ten time points to predict the next time point\n",
    "\n",
    "total_len_T = 10*60 # I just don't have that much time!\n",
    "total_len_n = total_len_T*srate_in\n",
    "data_idx = data_in.shape[1]//2 + np.arange(total_len_n)\n",
    "print('Downsampling data from {0} to {1}'.format(srate_in,srate_down))\n",
    "data_in = np.float32(sp.signal.decimate(data_in[:,data_idx],srate_in//srate_down,axis=-1))\n",
    "print('Data Size:\\t{}'.format(data_in.shape))\n",
    "\n",
    "# filter dead channels\n",
    "ch_rms = np.std(data_in,axis=-1)\n",
    "ch_m = np.mean(ch_rms)\n",
    "ch_low_lim = ch_m - 2*np.std(ch_rms)\n",
    "ch_up_lim = ch_m + 2*np.std(ch_rms)\n",
    "ch_idx = np.logical_and(ch_rms > ch_low_lim, ch_rms < ch_up_lim)\n",
    "ch_list = np.arange(num_ch)[ch_idx]\n",
    "num_ch_down = len(ch_list)\n",
    "print('Num. ch. used:\\t{}'.format(num_ch_down))\n",
    "print('Ch. dropped:\\t{}'.format(np.arange(num_ch)[np.logical_not(ch_idx)]))\n",
    "\n",
    "data_in = data_in[ch_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data covariances\n",
    "n_data = data_in.shape[-1]\n",
    "data_z = sp.stats.zscore(data_in,axis=-1)\n",
    "data_cov = np.cov(data_in)\n",
    "data_z_cov = np.cov(data_z)\n",
    "# full data covariance\n",
    "f,ax = plt.subplots(2,1,figsize=(10,14))\n",
    "plt.colorbar(ax[0].imshow(data_cov),ax=ax[0],label='Covariance')\n",
    "ax[0].set_title('ECoG Covariance')\n",
    "plt.colorbar(ax[1].imshow(data_z_cov),ax=ax[1],label='Covariance')\n",
    "ax[1].set_title('Normalized ECoG Covariance')\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot IQR stats for all channels\n",
    "data_z_iqr = np.percentile(data_z,[0,2.5,25,50,75,95.5,100],axis=-1)\n",
    "f,ax = plt.subplots(1,1,figsize=(12,6))\n",
    "ch_q_lines = ax.plot(ch_list,data_z_iqr.T)\n",
    "ax.legend(ch_q_lines,('min','2.5%','25%','50%','75%','95.5%','max'),bbox_to_anchor=(1.0, 1.05))\n",
    "ax.axhline(1,color='black',linestyle='--')\n",
    "ax.axhline(-1,color='black',linestyle='--')\n",
    "ax.set_xlabel('Channel ID')\n",
    "ax.set_ylabel('Norm. Amp.')\n",
    "ax.set_title('Quartile Ranges v. ECoG Channels')\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look @min/max values on 1s windows, 0.5s steps\n",
    "window_len = 125\n",
    "step_len = 125\n",
    "n_window = (n_data-window_len)//step_len\n",
    "min_max_win = np.zeros((2,n_window))\n",
    "for w_idx in range(n_window):\n",
    "    data_idx = w_idx*step_len + np.arange(window_len)\n",
    "    min_max_win[0,w_idx] = np.min(data_z[:,data_idx].reshape(-1))\n",
    "    min_max_win[1,w_idx] = np.max(data_z[:,data_idx].reshape(-1))\n",
    "win_t = 0.5 + np.arange(n_window)/2\n",
    "f, ax = plt.subplots(1,1,figsize=(12,3))\n",
    "mmlines = ax.plot(win_t,min_max_win.T)\n",
    "ax.set_xlabel('time (s)')\n",
    "ax.set_ylabel('norm. amp.')\n",
    "ax.set_title('Min, Max; all channels, norm.')\n",
    "ax.axhline(-1,color='black',linestyle='--')\n",
    "ax.axhline(1,color='black',linestyle='--')\n",
    "ax.legend(('min','max','±1'),bbox_to_anchor=(1.0, 1.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot IQR stats for all channels\n",
    "data_z_iqr = np.percentile(data_z/3,[0,2.5,25,50,75,95.5,100],axis=-1)\n",
    "f,ax = plt.subplots(1,1,figsize=(12,6))\n",
    "ch_q_lines = ax.plot(ch_list,data_z_iqr.T)\n",
    "ax.legend(ch_q_lines,('min','2.5%','25%','50%','75%','95.5%','max'),bbox_to_anchor=(1.05, 1.05))\n",
    "ax.axhline(1,color='black',linestyle='--')\n",
    "ax.axhline(-1,color='black',linestyle='--')\n",
    "ax.set_xlabel('Channel ID')\n",
    "ax.set_ylabel('Norm. Amp.')\n",
    "ax.set_title('Quartile Ranges v. ECoG Channels (*/3)')\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look @min/max values on 1s windows, 0.5s steps\n",
    "window_len = 125\n",
    "step_len = 125\n",
    "n_window = (n_data-window_len)//step_len\n",
    "min_max_win = np.zeros((2,n_window))\n",
    "for w_idx in range(n_window):\n",
    "    data_idx = w_idx*step_len + np.arange(window_len)\n",
    "    min_max_win[0,w_idx] = np.min(data_z[:,data_idx].reshape(-1))\n",
    "    min_max_win[1,w_idx] = np.max(data_z[:,data_idx].reshape(-1))\n",
    "win_t = 0.5 + np.arange(n_window)/2\n",
    "f, ax = plt.subplots(3,1,figsize=(12,9))\n",
    "ax[0].plot(win_t,min_max_win.T/3)\n",
    "ax[0].axhline(-1,color='black',linestyle='--')\n",
    "ax[0].axhline(1,color='black',linestyle='--')\n",
    "ax[1].plot(win_t,min_max_win.T/4)\n",
    "ax[1].axhline(-1,color='black',linestyle='--')\n",
    "ax[1].axhline(1,color='black',linestyle='--')\n",
    "ax[2].plot(win_t,min_max_win.T/5)\n",
    "ax[2].axhline(-1,color='black',linestyle='--')\n",
    "ax[2].axhline(1,color='black',linestyle='--')\n",
    "ax[0].legend(('min','max','±1'),bbox_to_anchor=(1.0, 1.05))\n",
    "ax[2].set_xlabel('time (s)')\n",
    "ax[1].set_ylabel('norm. amp.')\n",
    "ax[0].set_title('Min, Max; all channels, norm. (*/3, 4, 5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at histogram of tanh-norm data\n",
    "print(data_z.shape)\n",
    "data_z = data_z/3\n",
    "data_sig = np.tanh(data_z)\n",
    "data_sig.shape\n",
    "f,ax = plt.subplots(2,1)\n",
    "ax[0].hist(data_sig.reshape(-1),50)\n",
    "ax[1].plot(data_sig[0,:250*10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess effects of normalization on data - spectral characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mtpsd estimates from normalized data\n",
    "srate = srate_down\n",
    "win_t = 8.0\n",
    "over_t = 4.0\n",
    "del_f = 0.5 # desired bandwidth (Hz)\n",
    "bw = int(win_t * del_f /2)\n",
    "\n",
    "fz, tz, Sz = datafilter.mt_sgram(data_z,srate,win_t,over_t,bw,interp=False,mask=None)\n",
    "ft, tt, St = datafilter.mt_sgram(data_sig,srate,win_t,over_t,bw,interp=False,mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for spectrogram plotting; forgive the misnomer\n",
    "def plot_psd(ax,psd,x,y,clim,cmap='viridis'):\n",
    "    # create norm from clim\n",
    "    norm = plt.Normalize(vmin=clim[0],vmax=clim[1])\n",
    "    # get axes extent from x, y\n",
    "    extent = (x.min(), x.max(), y.min(), y.max())\n",
    "    # plot the figure\n",
    "    im_h = ax.imshow(10*np.log10(psd),extent=extent,norm=norm,origin='bottom')\n",
    "    # add a colorbar\n",
    "    cb_h = plt.colorbar(im_h, ax=ax, label='dB', pad=0.01)\n",
    "    \n",
    "    return im_h, cb_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot spectrograms\n",
    "f_psd,ax = plt.subplots(2,1,figsize=(20,8)) \n",
    "z_im_h, _ = plot_psd(ax[0],Sz[0,],tz,fz,(-50,-10))\n",
    "plot_psd(ax[1],St[0,],tt,ft,(-50,-10))\n",
    "ax[1].set_xlabel('Time (s)')\n",
    "ax[0].set_title('z-score')\n",
    "ax[1].set_title('z-score + tanh')\n",
    "f_psd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_z_mean_db = 10*np.log10(Sz.mean(axis=-1))\n",
    "psd_t_mean_db = 10*np.log10(St.mean(axis=-1))\n",
    "psd_diff_db = psd_z_mean_db - psd_t_mean_db\n",
    "\n",
    "f_log,ax = plt.subplots(2,1,figsize=(8,12),sharex=True)\n",
    "ax[0].plot(fz,psd_z_mean_db.T,color='green',alpha=0.2)\n",
    "ax[0].plot(ft,psd_t_mean_db.T,color='darkblue',alpha=0.2,label='tanh')\n",
    "leg_el_0 = [plt.Line2D([0],[0],color='green',linewidth=4,label='z-score')\n",
    "           ,plt.Line2D([0],[0],color='darkblue',linewidth=4,label='tanh')]\n",
    "ax[0].legend(handles=leg_el_0,loc=0)\n",
    "ax[0].set_ylabel('(dB)')\n",
    "ax[0].set_title('Normalized PSD Estimates, all channels')\n",
    "ax[1].plot(fz,psd_diff_db.T,color='k',alpha=0.2)\n",
    "leg_el_1 = [plt.Line2D([0],[0],color='k',linewidth=4,label='log diff.')]\n",
    "ax[1].legend(handles=leg_el_1,loc=0)\n",
    "ax[0].set_xlabel('Frequency (Hz)')\n",
    "ax[1].set_ylabel('(dB)')\n",
    "ax[1].set_title('Spectrum Difference, Log-scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the TVD derivative estimator\n",
    "n_plot = 125\n",
    "t = np.arange(n_plot)/srate_down\n",
    "d_data_sig = Tvregdiff.TVRegDiff(data_sig[0,:n_plot].squeeze(), itern=2, alph=10, u0=None, scale='large', ep=1e-6, dx=1/srate_down, plotflag=False)\n",
    "d_dummy = np.concatenate(([0],np.diff(data_sig[0,:n_plot].squeeze())))\n",
    "f,ax = plt.subplots(1,1,figsize=(12,8))\n",
    "ax.plot(t,data_sig[0,:n_plot])\n",
    "ax.plot(t,np.tanh(sp.stats.zscore(d_data_sig)/3))\n",
    "ax.plot(t,np.tanh(sp.stats.zscore(d_dummy)/3))\n",
    "print(d_data_sig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecog_is2s",
   "language": "python",
   "name": "ecog_is2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
