{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Encoder' from 'ecog_is2s' (/Users/mickey/anaconda3/envs/ecog_is2s/lib/python3.7/site-packages/ecog_is2s-0.1-py3.7.egg/ecog_is2s/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ccef1fe8941d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0maopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatareader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatafilter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mecog_is2s\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEcogDataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mecog_is2s\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeq2Seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mecog_is2s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Encoder' from 'ecog_is2s' (/Users/mickey/anaconda3/envs/ecog_is2s/lib/python3.7/site-packages/ecog_is2s-0.1-py3.7.egg/ecog_is2s/__init__.py)"
     ]
    }
   ],
   "source": [
    "from aopy import datareader, datafilter\n",
    "from ecog_is2s import EcogDataloader, Training\n",
    "from ecog_is2s.model import Encoder, Decoder, Seq2Seq\n",
    "from ecog_is2s.model import Util\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SequentialSampler, BatchSampler, SubsetRandomSampler\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import sklearn\n",
    "import scipy as sp\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "# import progressbar as pb\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import pickle as pkl\n",
    "\n",
    "# import argparse # add back in once this runs\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load, preprocess example data (same as training, so sue me)\n",
    "# seed RNG for pytorch/np\n",
    "SEED = 5050\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# set device - CUDA if you've got it\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('mounting to device: {}'.format(device))\n",
    "\n",
    "# load data\n",
    "platform_name = sys.platform\n",
    "if platform_name == 'darwin':\n",
    "    # local machine\n",
    "    data_file_full_path = '/Volumes/Samsung_T5/aoLab/Data/WirelessData/Goose_Multiscale_M1/180325/001/rec001.LM1_ECOG_3.clfp.dat'\n",
    "    mask_file_path = \"/Volumes/Samsung_T5/aoLab/Data/WirelessData/Goose_Multiscale_M1/180325/001/rec001.LM1_ECOG_3.clfp.mask.pkl\"\n",
    "    model_save_dir_path = '/Volumes/Samsung_T5/aoLab/Data/models/pyt/seq2seq/'\n",
    "elif platform_name == 'linux2':\n",
    "    # HYAK, baby!\n",
    "    data_file_full_path = '/gscratch/stf/manolan/Data/WirelessData/Goose_Multiscale_M1/180325/001/rec001.LM1_ECOG_3.clfp.dat'\n",
    "    mask_file_path = \"/gscratch/stf/manolan/Data/WirelessData/Goose_Multiscale_M1/180325/001/rec001.LM1_ECOG_3.clfp.mask.pkl\"\n",
    "elif platform_name == 'linux':\n",
    "    # google cloud, don't fail me now\n",
    "    data_file_full_path = '/home/mickey/rec001.LM1_ECOG_3.clfp.dat'\n",
    "    mask_file_path = '/home/mickey/rec001.LM1_ECOG_3.clfp.mask.pkl'\n",
    "    model_save_dir_path = '/home/mickey/models/pyt/seq2seq/'\n",
    "\n",
    "# make sure the output directory actually exists\n",
    "if not os.path.exists(model_save_dir_path):\n",
    "    os.makedirs(model_save_dir_path)\n",
    "\n",
    "data_in, data_param, data_mask = datareader.load_ecog_clfp_data(data_file_name=data_file_full_path)\n",
    "srate_in= data_param['srate']\n",
    "num_ch = data_param['num_ch']\n",
    "# we already found the appropriate data masks, so just load them in\n",
    "with open(mask_file_path, 'rb') as f:\n",
    "    mask_data = pkl.load(f)\n",
    "hf_mask = mask_data[\"hf\"]\n",
    "sat_mask = mask_data[\"sat\"]\n",
    "\n",
    "# mask data array, remove obvious outliers\n",
    "data_in[:,np.logical_or(hf_mask,sat_mask)] = 0.\n",
    "\n",
    "# downsample data\n",
    "srate_down = 250\n",
    "\n",
    "# create dataset object from file\n",
    "srate = srate_in\n",
    "# data_in = np.double(data_in[:,:120*srate])\n",
    "# enc_len = args.encoder_depth\n",
    "# dec_len = args.decoder_depth\n",
    "# seq_len = enc_len+dec_len # use ten time points to predict the next time point\n",
    "\n",
    "total_len_T = 1*60 # I just don't have that much time!\n",
    "total_len_n = total_len_T*srate_in\n",
    "data_idx = data_in.shape[1]//2 + np.arange(total_len_n)\n",
    "print('Downsampling data from {0} to {1}'.format(srate_in,srate_down))\n",
    "data_in = np.float32(sp.signal.decimate(data_in[:,data_idx],srate_in//srate_down,axis=-1))\n",
    "print('Data Size:\\t{}'.format(data_in.shape))\n",
    "\n",
    "# filter dead channels\n",
    "ch_rms = np.std(data_in,axis=-1)\n",
    "ch_m = np.mean(ch_rms)\n",
    "ch_low_lim = ch_m - 2*np.std(ch_rms)\n",
    "ch_up_lim = ch_m + 2*np.std(ch_rms)\n",
    "ch_idx = np.logical_and(ch_rms > ch_low_lim, ch_rms < ch_up_lim)\n",
    "ch_list = np.arange(num_ch)[ch_idx]\n",
    "num_ch_down = len(ch_list)\n",
    "print('Num. ch. used:\\t{}'.format(num_ch_down))\n",
    "print('Ch. dropped:\\t{}'.format(np.arange(num_ch)[np.logical_not(ch_idx)]))\n",
    "\n",
    "data_in = data_in[ch_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data statistics over windows\n",
    "n_data = data_in.shape[-1]\n",
    "data_z = sp.stats.zscore(data_in,axis=-1)\n",
    "data_cov = np.cov(data_in)\n",
    "data_z_cov = np.cov(data_z)\n",
    "# full data covariance\n",
    "f,ax = plt.subplots(2,1,figsize=(10,10))\n",
    "plt.colorbar(ax[0].imshow(data_cov),label='Covariance')\n",
    "ax[0].set_title('ECoG Covariance')\n",
    "# f.show()\n",
    "# f,ax = plt.subplots(1,1,figsize=(10,10))\n",
    "plt.colorbar(ax[1].imshow(data_z_cov,label='Normalized Data'),label='Covariance')\n",
    "ax[1].set_title('Normalized ECoG Covariance')\n",
    "f.show()\n",
    "# plot differences between standard deviations \n",
    "# print(np.mean(data_in,axis=-1),np.mean(data_z,axis=-1))\n",
    "# print(np.std(data_in,axis=-1),np.std(data_z,axis=-1))\n",
    "# n_row = 7\n",
    "# n_col = 8\n",
    "# f,ax = plt.subplots(7,8,figsize=(16,14))\n",
    "# # print(ax)\n",
    "# for r_i in range(n_row):\n",
    "#     for c_i in range(n_col):\n",
    "#         ch_i = r_i*n_col + c_i\n",
    "#         ax[r_i,c_i].plot(data_in[ch_i,:])\n",
    "# f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model from trained state dict\n",
    "device = torch.device('cpu')\n",
    "model_file_path = '/Volumes/Samsung_T5/aoLab/Data/models/pyt/seq2seq/enc1000_dec1000_nl2_2020042115161587482188/model_checkpoint.pt'\n",
    "model0_file_path = '/Volumes/Samsung_T5/aoLab/Data/models/pyt/seq2seq/enc1000_dec1000_nl2_2020042115161587482188/example_sequence_figs/data_tuple_epoch10.pt'\n",
    "model_def = torch.load(model_file_path,map_location=device)\n",
    "# model0_def = torch.load(model0_file_path,map_location=device)\n",
    "print(model_def['model_state_dict'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2,figsize=(10,8))\n",
    "ax[0].imshow(model_def['model_state_dict']['encoder.rnn.weight_ih_l0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecog_is2s",
   "language": "python",
   "name": "ecog_is2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
