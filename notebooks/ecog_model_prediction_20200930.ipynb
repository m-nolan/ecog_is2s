{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit ('ecog_is2s': conda)",
   "display_name": "Python 3.7.7 64-bit ('ecog_is2s': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fe8054fe0736511d0a995e424bd42fab5ba13013efdf79ed2907f82c79967e8d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "from os import makedirs, chmod\n",
    "import glob\n",
    "import functools\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import tqdm\n",
    "\n",
    "import aopy\n",
    "import ecog_is2s\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file list to dataset\n",
    "data_path_root = 'C:\\\\Users\\\\mickey\\\\aoLab\\\\Data\\\\WirelessData\\\\Goose_Multiscale_M1'\n",
    "data_path_day = path.join(data_path_root,'18032[5-7]')\n",
    "data_file_list = glob.glob(path.join(data_path_day,'0[0-9]*\\\\*ECOG*clfp_ds250.dat'))\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print('mounting to device: {}'.format(device))\n",
    "print(f'files found:\\t{len(data_file_list)}')\n",
    "print(f'files: {data_file_list}')\n",
    "datafile_list = [aopy.data.DataFile(df) for df in data_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_t = 1.0\n",
    "trg_t = 0.5\n",
    "step_t = src_t+trg_t\n",
    "diff_transform = ecog_is2s.Util.add_signal_diff() # no need for the srate parameter, dx est. is z-scored as well\n",
    "zscore_transform = ecog_is2s.Util.local_zscore()\n",
    "transform = lambda sample : diff_transform(zscore_transform(sample))\n",
    "dfds_list = [aopy.data.DatafileDataset(df,src_t,trg_t,step_t,device=device) for df in datafile_list]\n",
    "datafile_concatdataset = aopy.data.DatafileConcatDataset(dfds_list,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = (4,1,1)\n",
    "batch_size = 500\n",
    "train_loader, valid_loader, test_loader = datafile_concatdataset.get_data_loaders(partition=partition,batch_size=batch_size,rand_part=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ch = datafile_concatdataset.n_ch\n",
    "n_unit = 2**9\n",
    "n_layers = 1\n",
    "dropout = 0.3\n",
    "use_diff = True\n",
    "bidirectional = False\n",
    "model = ecog_is2s.Seq2Seq.Seq2Seq_GRU(input_dim=n_ch,hid_dim=n_unit,n_layers=n_layers,enc_len=0,dec_len=0,device=device,dropout=dropout,use_diff=use_diff,bidirectional=bidirectional).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load parameters from file\n",
    "model_path = \"D:\\\\Users\\\\mickey\\\\Data\\\\models\\\\pyt\\\\seq2seq\\\\\"\n",
    "model_name = \"enc1.0_dec0.5_srate250_20201010163509\"\n",
    "checkpoint_dict = torch.load(path.join(model_path,model_name,'checkpoint.pt'))\n",
    "model.load_state_dict(checkpoint_dict['model_state_dict'])\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trial_prediction(src,trg,out,srate=1,ch_idx=0,dpi=100,ax=None):\n",
    "    n_t_src, n_ch = src.shape\n",
    "    n_t_trg, _ = trg.shape\n",
    "    time_src = np.arange(n_t_src)/srate\n",
    "    time_trg = np.arange(n_t_trg)/srate + n_t_src/srate\n",
    "    err = trg - out\n",
    "    mse = (err**2).mean(axis=0)\n",
    "    if not ax:\n",
    "        f,ax = plt.subplots(1,1)\n",
    "    ax.plot(time_src,src[:,ch_idx],label='src')\n",
    "    ax.plot(time_trg,trg[:,ch_idx],label='trg')\n",
    "    ax.plot(time_trg,out[:,ch_idx],label='out')\n",
    "    ax.legend(loc=0)\n",
    "    ax.set_xlabel('time')\n",
    "    ax.set_ylabel('(a.u.)')\n",
    "    ax.set_title(f'ch. {ch_idx}, mse = {mse[ch_idx]:0.4f}')\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 100\n",
    "ch_idx = 20\n",
    "src, trg = datafile_concatdataset.__getitem__(sample_idx)\n",
    "out, enc, dec = model(src[None,:,:],trg[None,:,:])\n",
    "out = out.detach().numpy()\n",
    "enc = enc.detach().numpy()\n",
    "dec = dec.detach().numpy()\n",
    "f,ax = plt.subplots(2,1,dpi=100,constrained_layout=True)\n",
    "plot_trial_prediction(src,trg,out[0,:,:],srate=datafile_concatdataset.srate,ch_idx=ch_idx,ax=ax[0])\n",
    "plot_trial_prediction(enc[0,:,:],dec[0,:,:],np.zeros((dec.shape[1],dec.shape[2])),srate=datafile_concatdataset.srate,ch_idx=ch_idx,ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sample(dataset,sample_idx,model):\n",
    "    src, trg = dataset.__getitem__(sample_idx)\n",
    "    out, enc, dec = model(src[None,:,:],trg[None,:,:])\n",
    "    out = out.detach().numpy()\n",
    "    enc = enc.detach().numpy()\n",
    "    dec = dec.detach().numpy()\n",
    "    # get error\n",
    "    serr_time = (trg - out[0,:,:])**2\n",
    "    mse_ch = np.sqrt(serr_time.mean(axis=0))\n",
    "    mse = np.sqrt(serr_time.mean(axis=(0,1)))\n",
    "    strg_time = (trg - trg.mean(axis=0))**2\n",
    "    rpe_ch = mse_ch/np.sqrt(strg_time.mean(axis=0))\n",
    "    rpe = mse/np.sqrt(strg_time.mean(axis=(0,1)))\n",
    "    return mse_ch, mse, rpe_ch, rpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.empty((len(datafile_concatdataset)))\n",
    "mse_ch = np.empty((len(datafile_concatdataset),datafile_concatdataset.n_ch))\n",
    "rpe = np.empty((len(datafile_concatdataset)))\n",
    "rpe_ch = np.empty((len(datafile_concatdataset),datafile_concatdataset.n_ch))\n",
    "for sample_idx in tqdm.tqdm(range(len(datafile_concatdataset))):\n",
    "    mse_ch[sample_idx,:], mse[sample_idx], rpe_ch[sample_idx,:], rpe[sample_idx] = eval_sample(datafile_concatdataset,sample_idx,model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {\n",
    "    'model_file': path.join(model_path,model_name,'checkpoint.pt'),\n",
    "    'test_file_list': datafile_list,\n",
    "    'src_t': src_t,\n",
    "    'trg_t': trg_t,\n",
    "    'mse': mse,\n",
    "    'mse_ch': mse_ch,\n",
    "    'rpe': rpe,\n",
    "    'rpe_ch': rpe_ch\n",
    "}\n",
    "torch.save(result_dict,path.join(model_path,model_name,'test_result_data.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the performance metrics\n",
    "def plot_results(result_dict):\n",
    "    f,ax = plt.subplots(2,1,dpi=100)\n",
    "    ax[0].hist(result_dict['mse'],100,label='MSE')\n",
    "    ax[1].hist(result_dict['rpe'],100,label='RPE')\n",
    "plot_results(result_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}